{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import  os, glob\n",
    "import  random, csv\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import Activation, Dropout\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import to_rgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1=h5py.File(r\"D:\\dl\\stardata\\data\\new_train_6w.h5\",'r')\n",
    "file2=h5py.File(r\"D:\\dl\\stardata\\data\\new_val_1w.h5\",'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfr1=file1['specsfr_fib_p50']\n",
    "lgm1=file1['lgm_fib_p50']\n",
    "img1=file1['processed_images']\n",
    "\n",
    "sfr2=file2['specsfr_fib_p50']\n",
    "lgm2=file2['lgm_fib_p50']\n",
    "img2=file2['processed_images']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# 计算裁剪区域的左上角和右下角坐标\n",
    "original_length=152\n",
    "target_length=64\n",
    "left = (original_length - target_length) // 2\n",
    "top = (original_length - target_length) // 2\n",
    "right = left + target_length\n",
    "bottom = top + target_length\n",
    "\n",
    "cropped_images = []\n",
    "for image_array in img1:\n",
    "    # 裁剪并添加到裁剪后的图像数组\n",
    "    cropped_image = image_array[:, top:bottom, left:right]\n",
    "    cropped_images.append(cropped_image)\n",
    "\n",
    "img_rgb1=[to_rgb.dr2_rgb(i,['g','r','z'])  for i in cropped_images]\n",
    "img_rgb1 = np.array(img_rgb1)\n",
    "\n",
    "cropped_images = []\n",
    "for image_array in img2:\n",
    "    # 裁剪并添加到裁剪后的图像数组\n",
    "    cropped_image = image_array[:, top:bottom, left:right]\n",
    "    cropped_images.append(cropped_image)\n",
    "\n",
    "\n",
    "img_rgb2=[to_rgb.dr2_rgb(i,['g','r','z'])  for i in cropped_images]\n",
    "img_rgb2 = np.array(img_rgb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "#train sfr\n",
    "scaler_sfr_train=MinMaxScaler()\n",
    "scaler_sfr_1=np.array(sfr1).reshape(-1, 1)\n",
    "scaler_sfr_train.fit(scaler_sfr_1)\n",
    "scaler_sfr_1 = scaler_sfr_train.transform(scaler_sfr_1)\n",
    "#train lgm\n",
    "scaler_lgm_train=MinMaxScaler()\n",
    "scaler_lgm_1=np.array(lgm1).reshape(-1, 1)\n",
    "scaler_lgm_train.fit(scaler_lgm_1)\n",
    "scaler_lgm_1 = scaler_lgm_train.transform(scaler_lgm_1)\n",
    "# #val sfr\n",
    "# scaler_sfr_val=MinMaxScaler()\n",
    "scaler_sfr_2=np.array(sfr2).reshape(-1, 1)\n",
    "scaler_sfr_2 = scaler_sfr_train.transform(scaler_sfr_2)\n",
    "# #val lgm\n",
    "# scaler_lgm_val=MinMaxScaler()\n",
    "scaler_lgm_2=np.array(lgm2).reshape(-1, 1)\n",
    "scaler_lgm_2 = scaler_lgm_train.transform(scaler_lgm_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##g->2\n",
    "##r->1\n",
    "##z->0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## g波段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rgb1_0=[]\n",
    "img_rgb2_0=[]\n",
    "channel_index = 0\n",
    "for i in img_rgb1:\n",
    "    img_rgb1_0.append(i[:,:,channel_index])\n",
    "\n",
    "for i in img_rgb2:\n",
    "    img_rgb2_0.append(i[:,:,channel_index])\n",
    "\n",
    "img_rgb1_0 = [np.repeat(grayscale_image[..., np.newaxis], 3, axis=-1) for grayscale_image in img_rgb1_0]\n",
    "img_rgb2_0 = [np.repeat(grayscale_image[..., np.newaxis], 3, axis=-1) for grayscale_image in img_rgb2_0]\n",
    "img_rgb1_0=np.array(img_rgb1_0)\n",
    "img_rgb2_0=np.array(img_rgb2_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gz波段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img_rgb1_0=[]\n",
    "img_rgb2_0=[]\n",
    "for i in img_rgb1:\n",
    "    #img_rgb1_0.append(i[:,:,channel_index])\n",
    "    channel_z = i[:, :, 0]\n",
    "    channel_g = i[:, :, 2]\n",
    "    channel_0 = (channel_z + channel_g) / 2\n",
    "    img_rgb1_0.append(cv2.merge([channel_0,channel_g,channel_z]))\n",
    "\n",
    "for i in img_rgb2:\n",
    "    #img_rgb1_0.append(i[:,:,channel_index])\n",
    "    channel_z = i[:, :, 0]\n",
    "    channel_g = i[:, :, 2]\n",
    "    channel_0 = (channel_z + channel_g) / 2\n",
    "    img_rgb2_0.append(cv2.merge([channel_0,channel_g,channel_z]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rz波段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img_rgb1_0=[]\n",
    "img_rgb2_0=[]\n",
    "for i in img_rgb1:\n",
    "    #img_rgb1_0.append(i[:,:,channel_index])\n",
    "    channel_z = i[:, :, 0]\n",
    "    channel_r = i[:, :, 1]\n",
    "    channel_0 = (channel_z + channel_r) / 2\n",
    "    img_rgb1_0.append(cv2.merge([channel_0,channel_r,channel_z]))\n",
    "\n",
    "for i in img_rgb2:\n",
    "    #img_rgb1_0.append(i[:,:,channel_index])\n",
    "    channel_z = i[:, :, 0]\n",
    "    channel_r = i[:, :, 1]\n",
    "    channel_0 = (channel_z + channel_r) / 2\n",
    "    img_rgb2_0.append(cv2.merge([channel_0,channel_r,channel_z]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gr波段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img_rgb1_0=[]\n",
    "img_rgb2_0=[]\n",
    "for i in img_rgb1:\n",
    "    #img_rgb1_0.append(i[:,:,channel_index])\n",
    "    channel_g = i[:, :, 2]\n",
    "    channel_r = i[:, :, 1]\n",
    "    channel_0 = (channel_g + channel_r) / 2\n",
    "    img_rgb1_0.append(cv2.merge([channel_0,channel_r,channel_g]))\n",
    "\n",
    "for i in img_rgb2:\n",
    "    #img_rgb1_0.append(i[:,:,channel_index])\n",
    "    channel_g = i[:, :, 2]\n",
    "    channel_r = i[:, :, 1]\n",
    "    channel_0 = (channel_g + channel_r) / 2\n",
    "    img_rgb2_0.append(cv2.merge([channel_0,channel_r,channel_g]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"CPU\"):\n",
    "    train_ds=tf.data.Dataset.from_tensor_slices((\n",
    "        np.array(img_rgb1_0),\n",
    "        {\n",
    "            'output_1': scaler_lgm_1,\n",
    "            'output_2': scaler_sfr_1\n",
    "        }\n",
    "    ))\n",
    "    val_ds=tf.data.Dataset.from_tensor_slices((\n",
    "        np.array(img_rgb2_0),\n",
    "        {\n",
    "            'output_1': scaler_lgm_2,\n",
    "            'output_2': scaler_sfr_2\n",
    "        }\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_value = 3407\n",
    "tf.random.set_seed(seed_value)\n",
    "\n",
    "\n",
    "batch_size = 256\n",
    "train_ds = train_ds.shuffle(buffer_size=4000)  \n",
    "train_ds = train_ds.batch(batch_size)\n",
    "train_ds = train_ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "val_ds = val_ds.batch(batch_size)\n",
    "val_ds = val_ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#[I 2023-10-24 17:44:46,373] Trial 0 finished with value: 0.43707062204998565 and parameters: {'learning_rate': 0.0003044714144499721, 'dropout_rate': 0.2864134988249096, 'rate': 0.005698380041415703, 'dense_units': 1024}. Best is trial 0 with value: 0.43707062204998565.\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "input_layer = tf.keras.layers.Input(shape=(64, 64, 3))\n",
    "\n",
    "# 特征提取层\n",
    "feature_extractor_layer = hub.KerasLayer(\"https://www.kaggle.com/models/google/efficientnet-v2/frameworks/TensorFlow2/variations/imagenet1k-b3-feature-vector/versions/2\", trainable=True)(input_layer)\n",
    "\n",
    "# Dropout层\n",
    "dropout_layer = tf.keras.layers.Dropout(0.2864134988249096)(feature_extractor_layer)\n",
    "\n",
    "# 全连接层\n",
    "dense_layer = tf.keras.layers.Dense(1024, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.001))(dropout_layer)\n",
    "\n",
    "# 输出层1，与标签1的类型匹配\n",
    "output_1 = tf.keras.layers.Dense(1, activation='linear', name='output_1')(dense_layer)\n",
    "\n",
    "# 输出层2，与标签2的类型匹配\n",
    "output_2 = tf.keras.layers.Dense(1, activation='linear', name='output_2')(dense_layer)\n",
    "\n",
    "# 创建多输出模型\n",
    "final_model = tf.keras.models.Model(inputs=input_layer, outputs=[output_1, output_2])\n",
    "#Learning Rate: 0.0003, Dropout Rate: 0.5, Dense Units: 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "235/235 [==============================] - 49s 173ms/step - loss: 1.3088 - output_1_loss: 0.1338 - output_2_loss: 0.1423 - output_1_mae: 0.1338 - output_2_mae: 0.1423 - val_loss: 1.0822 - val_output_1_loss: 0.1399 - val_output_2_loss: 0.1218 - val_output_1_mae: 0.1399 - val_output_2_mae: 0.1218\n",
      "Epoch 2/100\n",
      "235/235 [==============================] - 39s 168ms/step - loss: 0.7932 - output_1_loss: 0.0650 - output_2_loss: 0.0923 - output_1_mae: 0.0650 - output_2_mae: 0.0923 - val_loss: 0.6530 - val_output_1_loss: 0.0917 - val_output_2_loss: 0.0910 - val_output_1_mae: 0.0917 - val_output_2_mae: 0.0910\n",
      "Epoch 3/100\n",
      "235/235 [==============================] - 39s 168ms/step - loss: 0.4963 - output_1_loss: 0.0585 - output_2_loss: 0.0861 - output_1_mae: 0.0585 - output_2_mae: 0.0861 - val_loss: 0.4110 - val_output_1_loss: 0.0706 - val_output_2_loss: 0.0894 - val_output_1_mae: 0.0706 - val_output_2_mae: 0.0894\n",
      "Epoch 4/100\n",
      "235/235 [==============================] - 39s 168ms/step - loss: 0.3244 - output_1_loss: 0.0558 - output_2_loss: 0.0837 - output_1_mae: 0.0558 - output_2_mae: 0.0837 - val_loss: 0.2705 - val_output_1_loss: 0.0529 - val_output_2_loss: 0.0873 - val_output_1_mae: 0.0529 - val_output_2_mae: 0.0873\n",
      "Epoch 5/100\n",
      "235/235 [==============================] - 39s 168ms/step - loss: 0.2303 - output_1_loss: 0.0547 - output_2_loss: 0.0799 - output_1_mae: 0.0547 - output_2_mae: 0.0799 - val_loss: 0.2241 - val_output_1_loss: 0.0600 - val_output_2_loss: 0.0965 - val_output_1_mae: 0.0600 - val_output_2_mae: 0.0965\n",
      "Epoch 6/100\n",
      "235/235 [==============================] - 39s 168ms/step - loss: 0.1832 - output_1_loss: 0.0531 - output_2_loss: 0.0795 - output_1_mae: 0.0531 - output_2_mae: 0.0795 - val_loss: 0.1805 - val_output_1_loss: 0.0548 - val_output_2_loss: 0.0890 - val_output_1_mae: 0.0548 - val_output_2_mae: 0.0890\n",
      "Epoch 7/100\n",
      "235/235 [==============================] - 39s 168ms/step - loss: 0.1566 - output_1_loss: 0.0513 - output_2_loss: 0.0772 - output_1_mae: 0.0513 - output_2_mae: 0.0772 - val_loss: 0.1644 - val_output_1_loss: 0.0487 - val_output_2_loss: 0.0946 - val_output_1_mae: 0.0487 - val_output_2_mae: 0.0946\n",
      "Epoch 8/100\n",
      "235/235 [==============================] - 39s 168ms/step - loss: 0.1434 - output_1_loss: 0.0509 - output_2_loss: 0.0757 - output_1_mae: 0.0509 - output_2_mae: 0.0757 - val_loss: 0.1554 - val_output_1_loss: 0.0485 - val_output_2_loss: 0.0937 - val_output_1_mae: 0.0485 - val_output_2_mae: 0.0937\n",
      "Epoch 9/100\n",
      "235/235 [==============================] - 39s 164ms/step - loss: 0.1349 - output_1_loss: 0.0491 - output_2_loss: 0.0746 - output_1_mae: 0.0491 - output_2_mae: 0.0746 - val_loss: 0.1408 - val_output_1_loss: 0.0466 - val_output_2_loss: 0.0851 - val_output_1_mae: 0.0466 - val_output_2_mae: 0.0851\n",
      "Epoch 10/100\n",
      "235/235 [==============================] - 39s 165ms/step - loss: 0.1283 - output_1_loss: 0.0480 - output_2_loss: 0.0724 - output_1_mae: 0.0480 - output_2_mae: 0.0724 - val_loss: 0.1349 - val_output_1_loss: 0.0454 - val_output_2_loss: 0.0827 - val_output_1_mae: 0.0454 - val_output_2_mae: 0.0827\n",
      "Epoch 11/100\n",
      "235/235 [==============================] - 39s 164ms/step - loss: 0.1258 - output_1_loss: 0.0474 - output_2_loss: 0.0724 - output_1_mae: 0.0474 - output_2_mae: 0.0724 - val_loss: 0.1426 - val_output_1_loss: 0.0471 - val_output_2_loss: 0.0903 - val_output_1_mae: 0.0471 - val_output_2_mae: 0.0903\n",
      "Epoch 12/100\n",
      "235/235 [==============================] - 39s 165ms/step - loss: 0.1218 - output_1_loss: 0.0465 - output_2_loss: 0.0706 - output_1_mae: 0.0465 - output_2_mae: 0.0706 - val_loss: 0.1271 - val_output_1_loss: 0.0463 - val_output_2_loss: 0.0764 - val_output_1_mae: 0.0463 - val_output_2_mae: 0.0764\n",
      "Epoch 13/100\n",
      "235/235 [==============================] - 39s 167ms/step - loss: 0.1192 - output_1_loss: 0.0454 - output_2_loss: 0.0698 - output_1_mae: 0.0454 - output_2_mae: 0.0698 - val_loss: 0.1399 - val_output_1_loss: 0.0478 - val_output_2_loss: 0.0884 - val_output_1_mae: 0.0478 - val_output_2_mae: 0.0884\n",
      "Epoch 14/100\n",
      "235/235 [==============================] - 39s 167ms/step - loss: 0.1172 - output_1_loss: 0.0451 - output_2_loss: 0.0686 - output_1_mae: 0.0451 - output_2_mae: 0.0686 - val_loss: 0.1289 - val_output_1_loss: 0.0472 - val_output_2_loss: 0.0784 - val_output_1_mae: 0.0472 - val_output_2_mae: 0.0784\n",
      "Epoch 15/100\n",
      "235/235 [==============================] - 39s 167ms/step - loss: 0.1156 - output_1_loss: 0.0445 - output_2_loss: 0.0679 - output_1_mae: 0.0445 - output_2_mae: 0.0679 - val_loss: 0.1348 - val_output_1_loss: 0.0532 - val_output_2_loss: 0.0786 - val_output_1_mae: 0.0532 - val_output_2_mae: 0.0786\n",
      "Epoch 16/100\n",
      "235/235 [==============================] - 39s 167ms/step - loss: 0.1137 - output_1_loss: 0.0438 - output_2_loss: 0.0670 - output_1_mae: 0.0438 - output_2_mae: 0.0670 - val_loss: 0.1384 - val_output_1_loss: 0.0481 - val_output_2_loss: 0.0875 - val_output_1_mae: 0.0481 - val_output_2_mae: 0.0875\n",
      "Epoch 17/100\n",
      "235/235 [==============================] - 39s 167ms/step - loss: 0.1101 - output_1_loss: 0.0425 - output_2_loss: 0.0649 - output_1_mae: 0.0425 - output_2_mae: 0.0649 - val_loss: 0.1291 - val_output_1_loss: 0.0480 - val_output_2_loss: 0.0785 - val_output_1_mae: 0.0480 - val_output_2_mae: 0.0785\n"
     ]
    }
   ],
   "source": [
    "#from tensorflow.keras.optimizers import legacy as keras_legacy_optimizers\n",
    "#I 2023-10-23 21:50:25,794] Trial 6 finished with value: 0.447093928745786 and parameters: {'learning_rate': 3.759682546092012e-05, 'dropout_rate': 0.017501915825131043, 'rate': 0.004768418909358573, 'dense_units': 256}. Best is trial 6 with value: 0.447093928745786.\n",
    "initial_learning_rate = 0.0003044714144499721\n",
    "# lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "#         initial_learning_rate, \n",
    "#         decay_steps=10,     \n",
    "#         decay_rate=0.1,   \n",
    "#         staircase=True)\n",
    "boundaries=[30,45]\n",
    "values=[initial_learning_rate,initial_learning_rate*0.1,initial_learning_rate*0.1*0.96]\n",
    "learning_rate_schedule = tf.keras.optimizers.schedules.PiecewiseConstantDecay(boundaries, values)\n",
    "\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=initial_learning_rate)\n",
    "#optimizer = keras_legacy_optimizers.Adam(learning_rate=1e-4)\n",
    "\n",
    "final_model.compile(optimizer=optimizer,\n",
    "               loss='mae',\n",
    "               metrics=['mae'])\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    min_delta=0.005,\n",
    "    patience=5\n",
    ")\n",
    "epoch=100\n",
    "history=final_model.fit(train_ds,\n",
    "            validation_data=val_ds,\n",
    "            validation_freq=1,\n",
    "            epochs=epoch,\n",
    "            callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model, save_model\n",
    "\n",
    "final_model.save(r'model/bound_gz.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file3=h5py.File(r\"D:\\dl\\stardata\\data\\new_test_3w_old.h5\",'r')\n",
    "img3=file3['processed_images']\n",
    "sfr_true=np.array(file3['specsfr_fib_p50']).reshape(-1,1)\n",
    "lgm_true=np.array(file3['lgm_fib_p50']).reshape(-1,1)\n",
    "import matplotlib.pyplot as plt\n",
    "# 计算裁剪区域的左上角和右下角坐标\n",
    "original_length=152\n",
    "target_length=64\n",
    "left = (original_length - target_length) // 2\n",
    "top = (original_length - target_length) // 2\n",
    "right = left + target_length\n",
    "bottom = top + target_length\n",
    "\n",
    "cropped_images = []\n",
    "for image_array in img3:\n",
    "    # 裁剪并添加到裁剪后的图像数组\n",
    "    cropped_image = image_array[:, top:bottom, left:right]\n",
    "    cropped_images.append(cropped_image)\n",
    "\n",
    "\n",
    "img_rgb3=[to_rgb.dr2_rgb(i,['g','r','z'])  for i in cropped_images]\n",
    "img_rgb3=np.array(img_rgb3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 单通道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rgb1=[]\n",
    "channel_index = 0\n",
    "for i in img_rgb3:\n",
    "    img_rgb1.append(i[:,:,channel_index])\n",
    "\n",
    "\n",
    "img_rgb1 = [np.repeat(grayscale_image[..., np.newaxis], 3, axis=-1) for grayscale_image in img_rgb1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多通道"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img_rgb1_gr=[]\n",
    "for i in img_rgb3:\n",
    "    #img_rgb1_0.append(i[:,:,channel_index])\n",
    "    channel_g = i[:, :, 0]\n",
    "    channel_r = i[:, :, 2]\n",
    "    channel_0 = (channel_g + channel_r) / 2\n",
    "    img_rgb1_gr.append(cv2.merge([channel_0,channel_r,channel_g]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "\n",
    "# 自定义对象字典，用于告诉 TensorFlow 如何处理自定义层\n",
    "custom_objects = {'KerasLayer': hub.KerasLayer}\n",
    "\n",
    "# 指定保存的模型文件路径\n",
    "model_path = 'model/bound_rz.h5'  # 替换为您的模型文件的实际路径\n",
    "\n",
    "# 加载模型并传递自定义对象字典\n",
    "final_model = tf.keras.models.load_model(model_path,custom_objects)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_mae(n1,n2):\n",
    "    # 计算绝对差值\n",
    "    n1=np.array(n1)\n",
    "    n2=np.array(n2)\n",
    "    absolute_errors = np.abs(n1 - n2)\n",
    "\n",
    "    # 计算平均绝对误差（MAE）\n",
    "    mae = np.mean(absolute_errors)\n",
    "\n",
    "    print(\"MAE:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_channel(model,img,name):\n",
    "    y=final_model.predict(np.array(img))\n",
    "    lgm_pred=np.array(y[0])\n",
    "    lgm_pred=scaler_lgm_train.inverse_transform(lgm_pred)\n",
    "\n",
    "    sfr_pred=np.array(y[1])\n",
    "    sfr_pred=scaler_sfr_train.inverse_transform(sfr_pred)\n",
    "    sd = np.std(np.array(lgm_true) - np.array(lgm_pred))\n",
    "    print(\"MAE for lgm:\")\n",
    "    count_mae(lgm_true,lgm_pred)\n",
    "    mse = np.mean((np.array(lgm_true) - np.array(lgm_pred)) ** 2)\n",
    "    rmse=np.sqrt(mse)\n",
    "    print(f'LGM的MSE是:{mse},RMSE是{rmse},SD是{sd}')\n",
    "    sd = np.std(np.array(sfr_true) - np.array(sfr_pred))\n",
    "    print(\"MAE for sfr:\")\n",
    "    count_mae(sfr_true,sfr_pred)\n",
    "\n",
    "    mse = np.mean((np.array(sfr_true) - np.array(sfr_pred)) ** 2)\n",
    "    rmse=np.sqrt(mse)\n",
    "    print(f'SFR的MSE是:{mse},RMSE是{rmse},SD是{sd}')\n",
    "\n",
    "    y_df=pd.DataFrame()\n",
    "    y_df['lgm']=pd.DataFrame(lgm_pred)\n",
    "    y_df['sfr']=pd.DataFrame(sfr_pred)\n",
    "\n",
    "    y_df.to_csv(f'result/{name}_bound_result.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
